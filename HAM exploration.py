# -*- coding: utf-8 -*-
"""FInal Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c8mDZVtIyrhVVa5hEliGegpRljkH9R8C

Final Project

#HAM 10000 has about 10,000 images of various skin lesions that have classifed into various categories, Over 50% of these were verifies with a followup physician's evaluation. I will attempt to make a CNN to classify these Images and assess it's accuracy
"""

from sklearn.metrics import confusion_matrix

import keras
from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization,MaxPool2D
from sklearn.model_selection import train_test_split
from scipy import stats
from sklearn.preprocessing import LabelEncoder

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from glob import glob
import seaborn as sns
from PIL import Image
import shutil
import zipfile
import seaborn as sns
import itertools
import tensorflow as tf
import sklearn


from tensorflow.keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from sklearn.model_selection import train_test_split

np.random.seed(42)

#print('Beginning file download with urllib2...')

#url=  'https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000/download'
#urllib.request.urlretrieve(url, '/content/HAM.zip')

os.getcwd()

from google.colab import drive
drive.mount('/gdrive')

os.chdir('/')
print(os.getcwd())
#os.listdir()
os.chdir('gdrive/MyDrive/Docs/')
#src = 'gdrive/MyDrive/Docs'
#os.chdir(src)
print(os.getcwd())
src = os.path.join(os.getcwd(),"HAM(images).zip")
os.chdir('/content')

if not os.path.exists ('/content/input/'):
    os.mkdir('/content/input')

dst = '/content/input/'
shutil.copy2(src, dst)

#to extract
os.chdir('/content/input')
with zipfile.ZipFile("HAM(images).zip","r") as zip_ref:
    zip_ref.extractall()

data = pd.DataFrame()


data= pd.read_csv('../input/hmnist_28_28_RGB.csv')

data.head()

"""This CSV file contains the data for the images by pixel as well as their label"""

data.columns

Label = data["label"]
data.drop('label', axis=1 , inplace= True)

Label.unique()

"""There are 5 labels"""

data2 = pd.read_csv('../input/HAM10000_metadata.csv')
data2.head(10)

"""The metadata shows us additional info about the patient localization of the lesion, age and other useful information"""

Label.value_counts()

plt.hist(Label)

"""These are just number however. The Metadata file shows us the diagnoses and by reading the studies associated with the data I came up with the diagnoses from the abbreviations in the metadata file I will demonstrate that below"""

lesion_type_dict = {
    'nv': 'Melanocytic nevi',
    'mel': 'Melanoma',
    'bkl': 'Benign keratosis-like lesions ',
    'bcc': 'Basal cell carcinoma',
    'akiec': 'Actinic keratoses',
    'vasc': 'Vascular lesions',
    'df': 'Dermatofibroma'
}

data2['diagnosis'] = data2['dx'].map(lesion_type_dict.get)

diagnoses = data2['diagnosis']
print(diagnoses.value_counts())
print(data2['dx'].value_counts())

"""##Here we can see from the above and previous RGB csv file that they match up as follows:
##0 - Actinic Keratoses
##1 - Basal Cell Carcinoma (BCC)
##2 - Benign Keratosis-Like Lesions(BKL)
##3 - Dermatofibroma (DF)
##4 - melanotic Nevi (NV)
##5 - Vascular Lesions(VASC)
##6 - Melanoma
"""

plt.figure(figsize= (16,9))
plt.hist(data2['diagnosis'])

"""##Now that we've seen the target variables lets look at other variables"""

print(data2['sex'].value_counts())

"""sex seems slightly skewed towards males in this dataset it is not drastic however there are a few Unknowns however."""

print(data2['localization'].value_counts())

"""One locality does not seem to dominate the others in this"""

print(data2['age'].value_counts())

plt.hist(data2['age'],bins=30)

"""The dataset for age seems skewed however lets take a closer look"""

data2['age'].value_counts()

sum(data2['age'].isna())

"""there are also 57 NA values I will impute these with the mean value"""

data2['age'].fillna((data2['age'].mean()), inplace=True)

sum(data2['age'].isna())

sns.scatterplot('age','dx',data=data2)

"""It seems BCC,Akiec and DF do not occur often in patients under about 20 years old"""

#sns.factorplot('sex','dx',data=data2)

"""Let's make the dataset more readable"""

base_skin_dir = os.path.join('..', 'input')

# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary

imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x
                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}

# Creating New Columns for better readability

data2['path'] = data2['image_id'].map(imageid_path_dict.get)
data2['cell_type'] = data2['dx'].map(lesion_type_dict.get) 
data2['cell_type_idx'] = pd.Categorical(data2['cell_type']).codes

data2.head(15)

"""Let's load and resize the images"""

data2['image'] = data2['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))

data2.head()

"""Lets print out some of these images"""

n_samples = 5
fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))
for n_axs, (type_name, type_rows) in zip(m_axs, 
                                         data2.sort_values(['cell_type']).groupby('cell_type')):
    n_axs[0].set_title(type_name)
    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):
        c_ax.imshow(c_row['image'])
        c_ax.axis('off')
fig.savefig('category_samples.png', dpi=300)

# Checking the image size distribution to make sure the resize worked
data2['image'].map(lambda x: x.shape).value_counts()

features=data2.drop(columns=['cell_type_idx'],axis=1)
target=data2['cell_type_idx']

"""Let's do a train test split"""

x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)

"""Let's Standardize the images since they are in numeric metadata-like form"""

x_train = np.asarray(x_train_o['image'].tolist())
x_test = np.asarray(x_test_o['image'].tolist())

x_train_mean = np.mean(x_train)
x_train_std = np.std(x_train)

x_test_mean = np.mean(x_test)
x_test_std = np.std(x_test)

x_train = (x_train - x_train_mean)/x_train_std
x_test = (x_test - x_test_mean)/x_test_std

print(x_train[:3])

"""Now to one-hot encode the Classes 0-6"""

# Perform one-hot encoding on the labels
y_train = to_categorical(y_train_o, num_classes = 7)
y_test = to_categorical(y_test_o, num_classes = 7)

"""Let's split the train in to train validate split"""

x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 321)

# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)
x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))
x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))
x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))

# Set the CNN model 
# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out
input_shape = (75, 100, 3)
num_classes = 7

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))
model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))
model.add(MaxPool2D(pool_size = (2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))
model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.40))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.summary()

optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)

model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])

"""As far as callbacks I tried both learning rate reduction and early stopping and early stopping seemed to perform slightly better on average"""

learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', 
                                            patience=3, 
                                            verbose=1, 
                                            factor=0.5, 
                                            min_lr=0.00001)

#callback for early stopping
callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=1e-3, restore_best_weights=True)

"""Data Augmentation to improve our model"""

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images

datagen.fit(x_train)

checkpoint_filepath = '/content/checkpoint/'

model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

#model.load_weights(checkpoint_filepath)

"""Lets train the model"""

epochs = 50 
batch_size = 10
history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = (x_validate,y_validate),
                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size
                              , callbacks=[callback,model_checkpoint_callback])

#getting train and validation accuracies
train_acc_CNN = history.history['accuracy']
val_acc_CNN = history.history['val_accuracy']

#getting train and validation losses
train_loss_CNN = history.history['loss']
val_loss_CNN = history.history['val_loss']
epochs = range(1, len(train_loss_CNN) + 1)

#plotting the training and validation accurracies
plt.plot(epochs, train_acc_CNN, 'b', label='Training acc')
plt.plot(epochs, val_acc_CNN, 'r', label='Validation acc')
plt.title('Training and validation accuracy for CNN')
plt.legend()
plt.figure()

#plotting the train and validaiton losses
plt.plot(epochs, train_loss_CNN, 'b', label='Training loss')
plt.plot(epochs, val_loss_CNN, 'r', label='Validation loss')
plt.title('Training and validation loss for CNN')
plt.legend()

plt.show()

# Function to plot confusion matrix    
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Predict the values from the validation dataset
Y_pred = model.predict(x_validate)
# Convert predictions classes to one hot vectors 
Y_pred_classes = np.argmax(Y_pred,axis = 1) 
# Convert validation observations to one hot vectors
Y_true = np.argmax(y_validate,axis = 1) 
# compute the confusion matrix
confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)

 

# plot the confusion matrix
plot_confusion_matrix(confusion_mtx, classes = range(7))

"""Let's see what fraction of the classes were classifed incorrectly"""

label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)
plt.bar(np.arange(7),label_frac_error)
plt.xlabel('True Label')
plt.ylabel('Fraction classified incorrectly')

"""Earlier we discovered
0 - Actinic Keratoses
1 - Basal Cell Carcinoma (BCC)
2 - Benign Keratosis-Like Lesions(BKL)
3 - Dermatofibroma (DF)
4 - melanotic Nevi (NV)
5 - Vascular Lesions(VASC)
6 - Melanoma

The model seems to have trouble classifying type 3 in particular type 3 being Dermatofibroma . The model also has significant trouble classifying type 0 which are Actinic keratoses. This isn't very surprising however as those have the least amount of samples in the dataset at at 115 and 327 samples respectively. The dataset gets the vast majority of type 4 (Melanotic Nevi) correct this class however had over 6000 samples. And in general the more samples there were the more accurate the model was
"""

#f1_score = sklearn.metrics.classification_report(Y_true, Y_pred)
